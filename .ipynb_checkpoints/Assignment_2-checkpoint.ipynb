{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2 Classify Images of Road Traffic Signs\n",
    "Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Lambda, Input\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data and categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_data():\n",
    "    image_list = []\n",
    "    for filepath in glob.glob('trafficsigns_dataset/*/*/*.png', recursive = True):\n",
    "        filename = filepath.split(\"/\")[-1]\n",
    "        sign_shape = filepath.split(\"/\")[1]\n",
    "        sign_type = filepath.split(\"/\")[2]\n",
    "        image_list.append((filepath, sign_shape, sign_type))\n",
    "        \n",
    "    data = pd.DataFrame(data=image_list, columns=['image_path','sign_shape', 'sign_type'])\n",
    "    # Convert string labels to numeric\n",
    "    d = {'diamond':0, 'hex':1, 'round':2, 'square':3, 'triangle':4}\n",
    "    data['labels_num'] = data['sign_shape'].map(d, na_action='ignore')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into training, validating and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2959, Test size: 740\n"
     ]
    }
   ],
   "source": [
    "trainData, validationData = train_test_split(load_img_data(), test_size=0.2, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "print('Train size: {}, Test size: {}'.format(trainData.shape[0], validationData.shape[0] ) )\n",
    "N_train_images = trainData.shape[0]\n",
    "N_val_images = validationData.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are serveral of function defined for training\n",
    "create and config a deep learning model cnn. varioius configuration will be tuned to get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape):\n",
    "    model_cnn = Sequential()\n",
    "\n",
    "    # input\n",
    "    model_cnn.add(Input(shape=(28, 28, 3)))\n",
    "    model_cnn.add(Lambda(lambda x: tf.expand_dims(x[:,:,:,0], -1, name=None))) \n",
    "\n",
    "    # Conv Layer 1\n",
    "    model_cnn.add(Conv2D(16, (3, 3),kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model_cnn.add(Activation('relu'))\n",
    "    model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # MLP\n",
    "    model_cnn.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model_cnn.add(Dense(64))\n",
    "    model_cnn.add(Activation('relu'))\n",
    "    model_cnn.add(Dropout(0.5))\n",
    "    model_cnn.add(Dense(shape))\n",
    "    model_cnn.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6)\n",
    "    model_cnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=[categorical_accuracy])\n",
    "\n",
    "    # save the weights so that we can start from the same place when tring different configurations\n",
    "    model_cnn.save_weights('model.h5')\n",
    "\n",
    "    return model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_, train_generator_in, validation_generator_in, num_epoch=50, verbose=False):\n",
    "    batch_size = 16\n",
    "    res = []\n",
    "    for e in range(num_epoch):\n",
    "        # print('Epoch', e)\n",
    "        batches = 0\n",
    "\n",
    "        loss_ = []\n",
    "        acc_ = []\n",
    "\n",
    "         # iterate over each batch\n",
    "        for x,y in train_generator_in:\n",
    "            loss, acc = model_.train_on_batch(x, y) # Update weights and return train loss, acc per batch\n",
    "            loss_.append(loss)\n",
    "            acc_.append(acc)\n",
    "            batches += 1\n",
    "            if batches >= N_train_images / batch_size:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "        loss_ = np.mean(loss_)\n",
    "        acc_ = np.mean(acc_)\n",
    "\n",
    "        loss, acc = calculate_losses(model_, validation_generator_in, N_val_images, batch_size)\n",
    "        if verbose:\n",
    "            print(\"Training epoch {}: Loss = {}, Accuracy = {}\".format(e, loss_, acc_))\n",
    "            print(\"Validation epoch {}: Loss = {}, Accuracy = {}\".format(e, loss, acc))\n",
    "\n",
    "        res.append((e, loss_, acc_, loss, acc))\n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "draw the graph and print numerical accuracy for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(res):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(res[:,0], res[:,1], 'r-')\n",
    "    plt.plot(res[:,0], res[:,3], 'b-')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim([0, np.max([5., np.max(res[:,1]), np.max(res[:,3])])])\n",
    "    print(\"Losses: \", res[:,3]);\n",
    "    plt.savefig('losses.png')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(res[:,0], res[:,2], 'r-')\n",
    "    plt.plot(res[:,0], res[:,4], 'b-')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, np.max([1., np.max(res[:,2]), np.max(res[:,4])])])\n",
    "    \n",
    "    print(\"Accuracy: \", res[:,4]);\n",
    "    plt.savefig('accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(model_in, data_generator_in, N_images, batch_size_):\n",
    "    loss_hold = []\n",
    "    acc_hold = []\n",
    "    batches = 0\n",
    "    \n",
    "    # iterate over each batch\n",
    "    for x,y in data_generator_in:\n",
    "        loss, acc = model_in.evaluate(x, y, verbose=0)\n",
    "        loss_hold.append(loss)\n",
    "        acc_hold.append(acc)\n",
    "        batches += 1\n",
    "        if batches >= N_images / batch_size_:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "            \n",
    "    return np.mean(loss_hold), np.mean(acc_hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate traning and validating/testing data to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(trainData, testData, target):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=trainData,\n",
    "            directory='./',\n",
    "            x_col=\"image_path\",\n",
    "            y_col=target,\n",
    "            target_size=(28, 28),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=testData,\n",
    "            directory='./',\n",
    "            x_col=\"image_path\",\n",
    "            y_col=target,\n",
    "            target_size=(28, 28),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "Found 2959 validated image filenames belonging to 5 classes.\n",
      "Found 740 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "modelcnn = create_model(5)\n",
    "train_generator, validation_generator = data_generator(trainData, validationData, \"sign_shape\")\n",
    "res = train_model(modelcnn, train_generator, validation_generator, num_epoch=100, verbose=False)\n",
    "plot_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn = create_model(16)\n",
    "train_generator, validation_generator = data_generator(trainData, validationData, \"sign_type\")\n",
    "res = train_model(modelcnn, train_generator, validation_generator, num_epoch=1, verbose=False)\n",
    "plot_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
